{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeticiaHms/data-collection-mba/blob/main/captura_ingestao_dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXrUt0dMBqx_"
      },
      "source": [
        "# üéì Aula Pr√°tica: Captura e Ingest√£o de Dados\n",
        "\n",
        "## Objetivos da Aula\n",
        "1. Capturar dados de APIs p√∫blicas\n",
        "2. Fazer web scraping b√°sico\n",
        "3. Simular ingest√£o de arquivos CSV/JSON\n",
        "4. Criar pipeline simples de ETL\n",
        "5. Introdu√ß√£o ao Airflow e dbt (conceitos)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99-Uepe9BqyL"
      },
      "source": [
        "## üì¶ Parte 1: Instala√ß√£o e Setup\n",
        "\n",
        "Vamos instalar as bibliotecas necess√°rias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-ecuPmBBqyR"
      },
      "outputs": [],
      "source": [
        "# Instalando bibliotecas necess√°rias\n",
        "!pip install requests pandas beautifulsoup4 sqlalchemy -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pzxmbqPBqyV"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "from typing import Dict, List\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0e506rsBqyY"
      },
      "source": [
        "---\n",
        "## üåê Parte 2: Captura de Dados de API\n",
        "\n",
        "### Exerc√≠cio 1: API REST simples\n",
        "Vamos usar a API p√∫blica JSONPlaceholder para simular captura de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A-lcYujBqya",
        "outputId": "33fae75b-6779-4be2-b545-21e0e25bbe61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de usu√°rios capturados: 10\n",
            "\n",
            "Primeiro usu√°rio:\n",
            "{\n",
            "  \"id\": 1,\n",
            "  \"name\": \"Leanne Graham\",\n",
            "  \"username\": \"Bret\",\n",
            "  \"email\": \"Sincere@april.biz\",\n",
            "  \"address\": {\n",
            "    \"street\": \"Kulas Light\",\n",
            "    \"suite\": \"Apt. 556\",\n",
            "    \"city\": \"Gwenborough\",\n",
            "    \"zipcode\": \"92998-3874\",\n",
            "    \"geo\": {\n",
            "      \"lat\": \"-37.3159\",\n",
            "      \"lng\": \"81.1496\"\n",
            "    }\n",
            "  },\n",
            "  \"phone\": \"1-770-736-8031 x56442\",\n",
            "  \"website\": \"hildegard.org\",\n",
            "  \"company\": {\n",
            "    \"name\": \"Romaguera-Crona\",\n",
            "    \"catchPhrase\": \"Multi-layered client-server neural-net\",\n",
            "    \"bs\": \"harness real-time e-markets\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Fun√ß√£o b√°sica para capturar dados de API\n",
        "def capturar_dados_api(url: str) -> Dict:\n",
        "    \"\"\"\n",
        "    Captura dados de uma API REST\n",
        "\n",
        "    Args:\n",
        "        url: URL da API\n",
        "\n",
        "    Returns:\n",
        "        Dados em formato JSON\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Levanta exce√ß√£o para erros HTTP\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Erro na requisi√ß√£o: {e}\")\n",
        "        return None\n",
        "\n",
        "# Testando a fun√ß√£o\n",
        "url = \"https://jsonplaceholder.typicode.com/users\"\n",
        "dados_usuarios = capturar_dados_api(url)\n",
        "\n",
        "print(f\"Total de usu√°rios capturados: {len(dados_usuarios)}\")\n",
        "print(\"\\nPrimeiro usu√°rio:\")\n",
        "print(json.dumps(dados_usuarios[0], indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrpUz1LkBqyd"
      },
      "source": [
        "### üí° DESAFIO 1: Capture dados de posts\n",
        "Complete a fun√ß√£o abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFsBB1AGBqyi"
      },
      "outputs": [],
      "source": [
        "def capturar_posts(limite: int = 10) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    TODO: Capturar posts da API\n",
        "    URL: https://jsonplaceholder.typicode.com/posts\n",
        "\n",
        "    Args:\n",
        "        limite: n√∫mero m√°ximo de posts a capturar\n",
        "\n",
        "    Returns:\n",
        "        Lista de posts\n",
        "    \"\"\"\n",
        "    # ESCREVA SEU C√ìDIGO AQUI\n",
        "    pass\n",
        "\n",
        "# Teste sua fun√ß√£o\n",
        "# posts = capturar_posts(5)\n",
        "# print(f\"Posts capturados: {len(posts)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnEGjDfVBqyk"
      },
      "source": [
        "---\n",
        "## üìä Parte 3: Transforma√ß√£o de Dados\n",
        "\n",
        "Vamos transformar os dados capturados em DataFrames do Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1-hbWwnBqyn",
        "outputId": "399509a0-e9cd-4c0a-b2f1-cdd77c8aa890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id              name   username                      email  \\\n",
            "0   1     Leanne Graham       Bret          Sincere@april.biz   \n",
            "1   2      Ervin Howell  Antonette          Shanna@melissa.tv   \n",
            "2   3  Clementine Bauch   Samantha         Nathan@yesenia.net   \n",
            "3   4  Patricia Lebsack   Karianne  Julianne.OConner@kory.org   \n",
            "4   5  Chelsey Dietrich     Kamren   Lucio_Hettinger@annie.ca   \n",
            "\n",
            "                   phone         cidade             empresa       lat  \\\n",
            "0  1-770-736-8031 x56442    Gwenborough     Romaguera-Crona  -37.3159   \n",
            "1    010-692-6593 x09125    Wisokyburgh        Deckow-Crist  -43.9509   \n",
            "2         1-463-123-4447  McKenziehaven  Romaguera-Jacobson  -68.6102   \n",
            "3      493-170-9623 x156    South Elvis       Robel-Corkery   29.4572   \n",
            "4          (254)954-1289     Roscoeview         Keebler LLC  -31.8129   \n",
            "\n",
            "         lng  \n",
            "0    81.1496  \n",
            "1   -34.4618  \n",
            "2   -47.0653  \n",
            "3  -164.2990  \n",
            "4    62.5342  \n",
            "\n",
            "Shape: (10, 9)\n"
          ]
        }
      ],
      "source": [
        "# Converter dados de usu√°rios para DataFrame\n",
        "def transformar_usuarios(dados_usuarios: List[Dict]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Transforma dados de usu√°rios em DataFrame normalizado\n",
        "    \"\"\"\n",
        "    # Criar DataFrame b√°sico\n",
        "    df = pd.DataFrame(dados_usuarios)\n",
        "\n",
        "    # Extrair informa√ß√µes aninhadas\n",
        "    df['cidade'] = df['address'].apply(lambda x: x['city'])\n",
        "    df['lat'] = df['address'].apply(lambda x: x['geo']['lat'])\n",
        "    df['lng'] = df['address'].apply(lambda x: x['geo']['lng'])\n",
        "    df['empresa'] = df['company'].apply(lambda x: x['name'])\n",
        "\n",
        "    # Selecionar colunas relevantes\n",
        "    colunas_finais = ['id', 'name', 'username', 'email', 'phone', 'cidade', 'empresa', 'lat', 'lng']\n",
        "\n",
        "    return df[colunas_finais]\n",
        "\n",
        "# Transformar dados\n",
        "df_usuarios = transformar_usuarios(dados_usuarios)\n",
        "print(df_usuarios.head())\n",
        "print(f\"\\nShape: {df_usuarios.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo68BXwdBqyp"
      },
      "source": [
        "### üí° DESAFIO 2: Adicione valida√ß√µes\n",
        "Adicione valida√ß√µes aos dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCYgyQY8Bqyq"
      },
      "outputs": [],
      "source": [
        "def validar_dados(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    TODO: Adicionar valida√ß√µes:\n",
        "    1. Remover linhas com email inv√°lido\n",
        "    2. Validar que lat/lng s√£o num√©ricos\n",
        "    3. Remover duplicatas\n",
        "    \"\"\"\n",
        "    # ESCREVA SEU C√ìDIGO AQUI\n",
        "    pass\n",
        "\n",
        "# Teste sua fun√ß√£o\n",
        "# df_validado = validar_dados(df_usuarios)\n",
        "# print(f\"Registros ap√≥s valida√ß√£o: {len(df_validado)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5BmbRNNBqys"
      },
      "source": [
        "---\n",
        "## üíæ Parte 4: Ingest√£o e Armazenamento\n",
        "\n",
        "### 4.1: Salvar em diferentes formatos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "7fEa8Z40Bqyt",
        "outputId": "3e0783b4-37d4-4040-b928-1a5cafde0d84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dados salvos em: dados_capturados/usuarios_20251024_010751.csv\n",
            "‚úÖ Dados salvos em: dados_capturados/usuarios_20251024_010751.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dados_capturados/usuarios_20251024_010751.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Criar diret√≥rio para dados\n",
        "os.makedirs('dados_capturados', exist_ok=True)\n",
        "\n",
        "def salvar_dados(df: pd.DataFrame, nome_arquivo: str, formato: str = 'csv'):\n",
        "    \"\"\"\n",
        "    Salva DataFrame em diferentes formatos\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame a ser salvo\n",
        "        nome_arquivo: nome base do arquivo (sem extens√£o)\n",
        "        formato: 'csv', 'json', 'parquet'\n",
        "    \"\"\"\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "    if formato == 'csv':\n",
        "        caminho = f'dados_capturados/{nome_arquivo}_{timestamp}.csv'\n",
        "        df.to_csv(caminho, index=False)\n",
        "    elif formato == 'json':\n",
        "        caminho = f'dados_capturados/{nome_arquivo}_{timestamp}.json'\n",
        "        df.to_json(caminho, orient='records', indent=2)\n",
        "    elif formato == 'parquet':\n",
        "        caminho = f'dados_capturados/{nome_arquivo}_{timestamp}.parquet'\n",
        "        df.to_parquet(caminho, index=False)\n",
        "\n",
        "    print(f\"‚úÖ Dados salvos em: {caminho}\")\n",
        "    return caminho\n",
        "\n",
        "# Salvar em diferentes formatos\n",
        "salvar_dados(df_usuarios, 'usuarios', 'csv')\n",
        "salvar_dados(df_usuarios, 'usuarios', 'json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7niSfiJBqyu"
      },
      "source": [
        "### 4.2: Simular banco de dados SQLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJYdJRSwBqyv",
        "outputId": "20ba69cd-5599-4c9c-8665-565f9deadbd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 10 registros inseridos na tabela 'usuarios'\n",
            "\n",
            "Amostra dos dados no banco:\n",
            "   id              name   username               email                  phone  \\\n",
            "0   1     Leanne Graham       Bret   Sincere@april.biz  1-770-736-8031 x56442   \n",
            "1   2      Ervin Howell  Antonette   Shanna@melissa.tv    010-692-6593 x09125   \n",
            "2   3  Clementine Bauch   Samantha  Nathan@yesenia.net         1-463-123-4447   \n",
            "\n",
            "          cidade             empresa       lat       lng  \\\n",
            "0    Gwenborough     Romaguera-Crona  -37.3159   81.1496   \n",
            "1    Wisokyburgh        Deckow-Crist  -43.9509  -34.4618   \n",
            "2  McKenziehaven  Romaguera-Jacobson  -68.6102  -47.0653   \n",
            "\n",
            "                data_ingestao  \n",
            "0  2025-10-24 01:13:15.238146  \n",
            "1  2025-10-24 01:13:15.238146  \n",
            "2  2025-10-24 01:13:15.238146  \n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Criar conex√£o com banco SQLite\n",
        "engine = create_engine('sqlite:///dados_capturados/dados.db')\n",
        "\n",
        "def ingerir_para_banco(df: pd.DataFrame, nome_tabela: str, engine):\n",
        "    \"\"\"\n",
        "    Ingere DataFrame em banco de dados\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Adicionar timestamp de ingest√£o\n",
        "        df['data_ingestao'] = datetime.now()\n",
        "\n",
        "        # Salvar no banco\n",
        "        df.to_sql(nome_tabela, engine, if_exists='replace', index=False)\n",
        "\n",
        "        print(f\"‚úÖ {len(df)} registros inseridos na tabela '{nome_tabela}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao inserir dados: {e}\")\n",
        "\n",
        "# Ingerir dados\n",
        "ingerir_para_banco(df_usuarios, 'usuarios', engine)\n",
        "\n",
        "# Verificar dados inseridos\n",
        "query = \"SELECT * FROM usuarios LIMIT 3\"\n",
        "resultado = pd.read_sql(query, engine)\n",
        "print(\"\\nAmostra dos dados no banco:\")\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGX_hkM3Bqyw"
      },
      "source": [
        "---\n",
        "## üîÑ Parte 5: Pipeline ETL Completo\n",
        "\n",
        "Vamos criar um pipeline que integra todas as etapas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuQ5b906Bqyx"
      },
      "outputs": [],
      "source": [
        "class PipelineETL:\n",
        "    \"\"\"\n",
        "    Pipeline ETL completo para captura e ingest√£o de dados\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, nome_pipeline: str):\n",
        "        self.nome = nome_pipeline\n",
        "        self.logs = []\n",
        "\n",
        "    def log(self, mensagem: str):\n",
        "        \"\"\"Adiciona log com timestamp\"\"\"\n",
        "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        log_msg = f\"[{timestamp}] {mensagem}\"\n",
        "        self.logs.append(log_msg)\n",
        "        print(log_msg)\n",
        "\n",
        "    def extrair(self, url: str) -> List[Dict]:\n",
        "        \"\"\"Extra√ß√£o de dados\"\"\"\n",
        "        self.log(f\"üîµ Iniciando extra√ß√£o de: {url}\")\n",
        "        dados = capturar_dados_api(url)\n",
        "        self.log(f\"‚úÖ Extra√≠dos {len(dados)} registros\")\n",
        "        return dados\n",
        "\n",
        "    def transformar(self, dados: List[Dict], funcao_transformacao) -> pd.DataFrame:\n",
        "        \"\"\"Transforma√ß√£o de dados\"\"\"\n",
        "        self.log(\"üîµ Iniciando transforma√ß√£o\")\n",
        "        df = funcao_transformacao(dados)\n",
        "        self.log(f\"‚úÖ Transforma√ß√£o conclu√≠da. Shape: {df.shape}\")\n",
        "        return df\n",
        "\n",
        "    def carregar(self, df: pd.DataFrame, destino: str, **kwargs):\n",
        "        \"\"\"Carregamento de dados\"\"\"\n",
        "        self.log(f\"üîµ Iniciando carregamento para: {destino}\")\n",
        "\n",
        "        if destino == 'csv':\n",
        "            salvar_dados(df, kwargs.get('nome', 'dados'), 'csv')\n",
        "        elif destino == 'banco':\n",
        "            ingerir_para_banco(df, kwargs.get('tabela', 'dados'), kwargs.get('engine'))\n",
        "\n",
        "        self.log(\"‚úÖ Carregamento conclu√≠do\")\n",
        "\n",
        "    def executar(self, url: str, funcao_transformacao, destino: str, **kwargs):\n",
        "        \"\"\"Executa pipeline completo\"\"\"\n",
        "        self.log(f\"üöÄ Iniciando pipeline: {self.nome}\")\n",
        "        inicio = time.time()\n",
        "\n",
        "        try:\n",
        "            # ETL\n",
        "            dados = self.extrair(url)\n",
        "            df = self.transformar(dados, funcao_transformacao)\n",
        "            self.carregar(df, destino, **kwargs)\n",
        "\n",
        "            # Finaliza√ß√£o\n",
        "            tempo_total = time.time() - inicio\n",
        "            self.log(f\"‚úÖ Pipeline conclu√≠do em {tempo_total:.2f} segundos\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log(f\"‚ùå Erro no pipeline: {e}\")\n",
        "            raise\n",
        "\n",
        "# Executar pipeline\n",
        "pipeline = PipelineETL(\"Pipeline de Usu√°rios\")\n",
        "pipeline.executar(\n",
        "    url=\"https://jsonplaceholder.typicode.com/users\",\n",
        "    funcao_transformacao=transformar_usuarios,\n",
        "    destino='banco',\n",
        "    tabela='usuarios_pipeline',\n",
        "    engine=engine\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrV3pbQ8Bqyz"
      },
      "source": [
        "### üí° DESAFIO 3: Crie seu pr√≥prio pipeline\n",
        "Crie um pipeline para capturar dados de posts e coment√°rios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W42JfHrPBqy0"
      },
      "outputs": [],
      "source": [
        "def transformar_posts(dados_posts: List[Dict]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    TODO: Transformar dados de posts\n",
        "    - Criar DataFrame\n",
        "    - Adicionar coluna com tamanho do t√≠tulo\n",
        "    - Adicionar coluna com tamanho do corpo\n",
        "    \"\"\"\n",
        "    # ESCREVA SEU C√ìDIGO AQUI\n",
        "    pass\n",
        "\n",
        "# TODO: Execute o pipeline para posts\n",
        "# pipeline_posts = PipelineETL(\"Pipeline de Posts\")\n",
        "# pipeline_posts.executar(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iYA6S7cBqy1"
      },
      "source": [
        "---\n",
        "## üåä Parte 6: Conceitos de Airflow (Simula√ß√£o)\n",
        "\n",
        "N√£o podemos executar Airflow no Colab, mas vamos simular os conceitos principais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMQsM8uEBqy1"
      },
      "outputs": [],
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "class TaskSimulada:\n",
        "    \"\"\"Simula uma Task do Airflow\"\"\"\n",
        "\n",
        "    def __init__(self, task_id: str, funcao):\n",
        "        self.task_id = task_id\n",
        "        self.funcao = funcao\n",
        "        self.status = \"PENDING\"\n",
        "\n",
        "    def executar(self, **kwargs):\n",
        "        \"\"\"Executa a task\"\"\"\n",
        "        print(f\"\\nüîµ Executando task: {self.task_id}\")\n",
        "        self.status = \"RUNNING\"\n",
        "\n",
        "        try:\n",
        "            resultado = self.funcao(**kwargs)\n",
        "            self.status = \"SUCCESS\"\n",
        "            print(f\"‚úÖ Task {self.task_id} conclu√≠da\")\n",
        "            return resultado\n",
        "        except Exception as e:\n",
        "            self.status = \"FAILED\"\n",
        "            print(f\"‚ùå Task {self.task_id} falhou: {e}\")\n",
        "            raise\n",
        "\n",
        "class DAGSimulada:\n",
        "    \"\"\"Simula uma DAG do Airflow\"\"\"\n",
        "\n",
        "    def __init__(self, dag_id: str, descricao: str):\n",
        "        self.dag_id = dag_id\n",
        "        self.descricao = descricao\n",
        "        self.tasks = []\n",
        "\n",
        "    def adicionar_task(self, task: TaskSimulada):\n",
        "        \"\"\"Adiciona uma task √† DAG\"\"\"\n",
        "        self.tasks.append(task)\n",
        "\n",
        "    def executar(self):\n",
        "        \"\"\"Executa todas as tasks em sequ√™ncia\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"üöÄ Executando DAG: {self.dag_id}\")\n",
        "        print(f\"Descri√ß√£o: {self.descricao}\")\n",
        "        print(f\"Total de tasks: {len(self.tasks)}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        resultado_anterior = None\n",
        "\n",
        "        for task in self.tasks:\n",
        "            resultado_anterior = task.executar(dados_anteriores=resultado_anterior)\n",
        "\n",
        "        print(f\"\\n‚úÖ DAG {self.dag_id} conclu√≠da com sucesso!\")\n",
        "\n",
        "# Exemplo de uso\n",
        "def task_extrair_usuarios(**kwargs):\n",
        "    url = \"https://jsonplaceholder.typicode.com/users\"\n",
        "    return capturar_dados_api(url)\n",
        "\n",
        "def task_transformar_usuarios(**kwargs):\n",
        "    dados = kwargs.get('dados_anteriores')\n",
        "    return transformar_usuarios(dados)\n",
        "\n",
        "def task_salvar_usuarios(**kwargs):\n",
        "    df = kwargs.get('dados_anteriores')\n",
        "    salvar_dados(df, 'usuarios_dag', 'csv')\n",
        "    return df\n",
        "\n",
        "# Criar DAG\n",
        "dag = DAGSimulada(\n",
        "    dag_id=\"pipeline_usuarios_v1\",\n",
        "    descricao=\"Pipeline di√°rio de captura de usu√°rios\"\n",
        ")\n",
        "\n",
        "# Adicionar tasks\n",
        "dag.adicionar_task(TaskSimulada(\"extrair_usuarios\", task_extrair_usuarios))\n",
        "dag.adicionar_task(TaskSimulada(\"transformar_usuarios\", task_transformar_usuarios))\n",
        "dag.adicionar_task(TaskSimulada(\"salvar_usuarios\", task_salvar_usuarios))\n",
        "\n",
        "# Executar DAG\n",
        "dag.executar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFtD5dZLBqy3"
      },
      "source": [
        "---\n",
        "## üìä Parte 7: Conceitos de dbt (Simula√ß√£o)\n",
        "\n",
        "Vamos simular transforma√ß√µes no estilo dbt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQ4uD3YLBqy4"
      },
      "outputs": [],
      "source": [
        "# Simulando models do dbt\n",
        "\n",
        "# Model 1: staging (dados brutos limpos)\n",
        "def stg_usuarios(engine):\n",
        "    \"\"\"\n",
        "    Model de staging - primeira camada de transforma√ß√£o\n",
        "    Similar a um arquivo .sql no dbt\n",
        "    \"\"\"\n",
        "    query = \"\"\"\n",
        "    SELECT\n",
        "        id as usuario_id,\n",
        "        name as nome_completo,\n",
        "        username,\n",
        "        email,\n",
        "        cidade,\n",
        "        empresa,\n",
        "        CAST(lat AS FLOAT) as latitude,\n",
        "        CAST(lng AS FLOAT) as longitude\n",
        "    FROM usuarios\n",
        "    WHERE email IS NOT NULL\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_sql(query, engine)\n",
        "    print(f\"‚úÖ stg_usuarios: {len(df)} registros\")\n",
        "    return df\n",
        "\n",
        "# Model 2: intermediate (l√≥gica de neg√≥cio)\n",
        "def int_usuarios_com_metricas(df_staging):\n",
        "    \"\"\"\n",
        "    Model intermediate - adiciona m√©tricas e c√°lculos\n",
        "    \"\"\"\n",
        "    df = df_staging.copy()\n",
        "\n",
        "    # Adicionar m√©tricas\n",
        "    df['tamanho_nome'] = df['nome_completo'].str.len()\n",
        "    df['tem_dominio_comercial'] = df['email'].str.contains('.com', na=False)\n",
        "    df['hemisferio'] = df['latitude'].apply(lambda x: 'Norte' if x > 0 else 'Sul')\n",
        "\n",
        "    print(f\"‚úÖ int_usuarios_com_metricas: {len(df)} registros\")\n",
        "    return df\n",
        "\n",
        "# Model 3: marts (modelo final para consumo)\n",
        "def mart_usuarios_resumo(df_intermediate):\n",
        "    \"\"\"\n",
        "    Model final - agrega√ß√µes e dados prontos para an√°lise\n",
        "    \"\"\"\n",
        "    resumo = df_intermediate.groupby('cidade').agg({\n",
        "        'usuario_id': 'count',\n",
        "        'tamanho_nome': 'mean',\n",
        "        'tem_dominio_comercial': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    resumo.columns = ['cidade', 'total_usuarios', 'media_tamanho_nome', 'usuarios_email_comercial']\n",
        "\n",
        "    print(f\"‚úÖ mart_usuarios_resumo: {len(resumo)} registros\")\n",
        "    return resumo\n",
        "\n",
        "# Executar pipeline dbt-style\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üîÑ Executando transforma√ß√µes estilo dbt\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Stage\n",
        "df_stg = stg_usuarios(engine)\n",
        "\n",
        "# Intermediate\n",
        "df_int = int_usuarios_com_metricas(df_stg)\n",
        "\n",
        "# Marts\n",
        "df_mart = mart_usuarios_resumo(df_int)\n",
        "\n",
        "print(\"\\nüìä Resultado Final:\")\n",
        "print(df_mart)\n",
        "\n",
        "# Salvar resultado final\n",
        "ingerir_para_banco(df_mart, 'mart_usuarios_resumo', engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xBNLjI1Bqy5"
      },
      "source": [
        "---\n",
        "## üéØ Parte 8: Exerc√≠cio Final Integrado\n",
        "\n",
        "Agora √© sua vez! Crie um pipeline completo que:\n",
        "1. Captura dados de posts E coment√°rios\n",
        "2. Faz JOIN entre as duas fontes\n",
        "3. Cria m√©tricas agregadas\n",
        "4. Salva em formato final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bdfqk5BBqy5"
      },
      "outputs": [],
      "source": [
        "# TODO: Seu pipeline completo aqui\n",
        "\n",
        "# URLs dispon√≠veis:\n",
        "# Posts: https://jsonplaceholder.typicode.com/posts\n",
        "# Coment√°rios: https://jsonplaceholder.typicode.com/comments\n",
        "\n",
        "# Estrutura sugerida:\n",
        "# 1. Criar classe ou fun√ß√£o para capturar ambos os dados\n",
        "# 2. Transformar e fazer JOIN (postId √© a chave)\n",
        "# 3. Calcular m√©tricas (ex: n√∫mero de coment√°rios por post)\n",
        "# 4. Criar visualiza√ß√£o simples dos resultados\n",
        "\n",
        "# ESCREVA SEU C√ìDIGO AQUI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jme5s8lDBqy6"
      },
      "source": [
        "---\n",
        "## üìö Resumo e Conceitos Importantes\n",
        "\n",
        "### O que aprendemos:\n",
        "\n",
        "1. **Extra√ß√£o de Dados**\n",
        "   - APIs REST com requests\n",
        "   - Tratamento de erros\n",
        "   - Pagina√ß√£o e limites\n",
        "\n",
        "2. **Transforma√ß√£o**\n",
        "   - Normaliza√ß√£o de dados\n",
        "   - Valida√ß√µes\n",
        "   - Limpeza e enriquecimento\n",
        "\n",
        "3. **Carregamento**\n",
        "   - M√∫ltiplos formatos (CSV, JSON, Parquet)\n",
        "   - Bancos de dados SQL\n",
        "   - Versionamento com timestamps\n",
        "\n",
        "4. **Pipelines**\n",
        "   - Orquestra√ß√£o de tarefas\n",
        "   - Logging e monitoramento\n",
        "   - Tratamento de erros\n",
        "\n",
        "5. **Conceitos Airflow**\n",
        "   - DAGs (Directed Acyclic Graphs)\n",
        "   - Tasks e depend√™ncias\n",
        "   - Agendamento\n",
        "\n",
        "6. **Conceitos dbt**\n",
        "   - Modelos em camadas (staging, intermediate, marts)\n",
        "   - Transforma√ß√µes SQL\n",
        "   - Documenta√ß√£o e testes\n",
        "\n",
        "### Pr√≥ximos passos:\n",
        "- Instalar Airflow localmente\n",
        "- Criar projeto dbt real\n",
        "- Explorar conectores para diferentes fontes de dados\n",
        "- Implementar data quality checks\n",
        "- Adicionar monitoramento e alertas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8F3jx_lBqy6"
      },
      "source": [
        "---\n",
        "## üîó Recursos Adicionais\n",
        "\n",
        "- [Documenta√ß√£o Airflow](https://airflow.apache.org/docs/)\n",
        "- [Documenta√ß√£o dbt](https://docs.getdbt.com/)\n",
        "- [APIs p√∫blicas para praticar](https://github.com/public-apis/public-apis)\n",
        "- [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/index.html)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}